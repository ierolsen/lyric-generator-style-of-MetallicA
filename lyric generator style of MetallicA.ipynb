{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from keras import regularizers\n",
    "import keras.utils as ku \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('lyrics.txt', encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = data.lower().split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create input sequences using list of tokens\n",
    "input_sequences = []\n",
    "for line in corpus:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pad sequences \n",
    "max_sequence_len = max([len(x) for x in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictors and label\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = ku.to_categorical(label, num_classes=total_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_sequence_len-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda\\envs\\tensor_v2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From d:\\anaconda\\envs\\tensor_v2\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 14, 100)           287200    \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 14, 300)           301200    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 300)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 100)               160400    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1436)              145036    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2872)              4127064   \n",
      "=================================================================\n",
      "Total params: 5,020,900\n",
      "Trainable params: 5,020,900\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(Bidirectional(LSTM(150, return_sequences = True)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(100))\n",
    "model.add(Dense(int(total_words/2), activation='relu', kernel_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\anaconda\\envs\\tensor_v2\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/300\n",
      "20971/20971 [==============================] - 65s 3ms/step - loss: 6.4624 - acc: 0.0494\n",
      "Epoch 2/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 6.0140 - acc: 0.0523\n",
      "Epoch 3/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 5.8143 - acc: 0.0542\n",
      "Epoch 4/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 5.6570 - acc: 0.0563\n",
      "Epoch 5/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 5.5196 - acc: 0.0662\n",
      "Epoch 6/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 5.3953 - acc: 0.0790\n",
      "Epoch 7/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 5.2657 - acc: 0.0920\n",
      "Epoch 8/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 5.1389 - acc: 0.1024\n",
      "Epoch 9/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 5.0117 - acc: 0.1144\n",
      "Epoch 10/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.8847 - acc: 0.1318\n",
      "Epoch 11/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.7645 - acc: 0.1433\n",
      "Epoch 12/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.6591 - acc: 0.1551\n",
      "Epoch 13/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.5441 - acc: 0.1691\n",
      "Epoch 14/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.4378 - acc: 0.1826\n",
      "Epoch 15/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.3337 - acc: 0.1946\n",
      "Epoch 16/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.2245 - acc: 0.2108\n",
      "Epoch 17/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.1181 - acc: 0.2258\n",
      "Epoch 18/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 4.0118 - acc: 0.2447\n",
      "Epoch 19/300\n",
      "20971/20971 [==============================] - 48s 2ms/step - loss: 3.9116 - acc: 0.2586\n",
      "Epoch 20/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.8112 - acc: 0.2778\n",
      "Epoch 21/300\n",
      "20971/20971 [==============================] - 48s 2ms/step - loss: 3.7045 - acc: 0.2940\n",
      "Epoch 22/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.6128 - acc: 0.3082\n",
      "Epoch 23/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.5167 - acc: 0.3227\n",
      "Epoch 24/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.4161 - acc: 0.3400\n",
      "Epoch 25/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.3421 - acc: 0.3543\n",
      "Epoch 26/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.2589 - acc: 0.3698\n",
      "Epoch 27/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.1689 - acc: 0.3819\n",
      "Epoch 28/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.0946 - acc: 0.3980\n",
      "Epoch 29/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 3.0237 - acc: 0.4117\n",
      "Epoch 30/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.9478 - acc: 0.4275\n",
      "Epoch 31/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.8759 - acc: 0.4377\n",
      "Epoch 32/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.8115 - acc: 0.4505\n",
      "Epoch 33/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.7608 - acc: 0.4560\n",
      "Epoch 34/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.6993 - acc: 0.4723\n",
      "Epoch 35/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.6381 - acc: 0.4844\n",
      "Epoch 36/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.5807 - acc: 0.4975\n",
      "Epoch 37/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.5275 - acc: 0.5068\n",
      "Epoch 38/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.4819 - acc: 0.5209: 0s - loss: 2.4822 - acc: 0.5\n",
      "Epoch 39/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.4227 - acc: 0.5263\n",
      "Epoch 40/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.3803 - acc: 0.5364\n",
      "Epoch 41/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.3408 - acc: 0.5437\n",
      "Epoch 42/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.2899 - acc: 0.5536\n",
      "Epoch 43/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.2493 - acc: 0.5636\n",
      "Epoch 44/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.2069 - acc: 0.5705\n",
      "Epoch 45/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.1709 - acc: 0.5790\n",
      "Epoch 46/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.1248 - acc: 0.5884\n",
      "Epoch 47/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.0938 - acc: 0.5940\n",
      "Epoch 48/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.0490 - acc: 0.6024\n",
      "Epoch 49/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 2.0147 - acc: 0.6090\n",
      "Epoch 50/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.9814 - acc: 0.6168\n",
      "Epoch 51/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.9549 - acc: 0.6220\n",
      "Epoch 52/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.9213 - acc: 0.6254\n",
      "Epoch 53/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.8850 - acc: 0.6389\n",
      "Epoch 54/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.8758 - acc: 0.6337\n",
      "Epoch 55/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.8330 - acc: 0.6440\n",
      "Epoch 56/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.8037 - acc: 0.6515: 0s - loss: 1.8017 - acc: 0.\n",
      "Epoch 57/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.7813 - acc: 0.6577\n",
      "Epoch 58/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.7600 - acc: 0.6606\n",
      "Epoch 59/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.7287 - acc: 0.6662\n",
      "Epoch 60/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.7122 - acc: 0.6704\n",
      "Epoch 61/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.6837 - acc: 0.6745: 1s - loss: 1.\n",
      "Epoch 62/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.6598 - acc: 0.6802\n",
      "Epoch 63/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.6629 - acc: 0.6784\n",
      "Epoch 64/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.6282 - acc: 0.6842\n",
      "Epoch 65/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.6008 - acc: 0.6895\n",
      "Epoch 66/300\n",
      "20971/20971 [==============================] - 48s 2ms/step - loss: 1.5787 - acc: 0.6970\n",
      "Epoch 67/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.5568 - acc: 0.7005\n",
      "Epoch 68/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.5485 - acc: 0.7006\n",
      "Epoch 69/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.5348 - acc: 0.7009\n",
      "Epoch 70/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.5136 - acc: 0.7074\n",
      "Epoch 71/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4984 - acc: 0.7088\n",
      "Epoch 72/300\n",
      "20971/20971 [==============================] - 48s 2ms/step - loss: 1.4764 - acc: 0.7120\n",
      "Epoch 73/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4636 - acc: 0.7165\n",
      "Epoch 74/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4499 - acc: 0.7188: 1s - loss: \n",
      "Epoch 75/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4358 - acc: 0.7227\n",
      "Epoch 76/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4406 - acc: 0.7201\n",
      "Epoch 77/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 1.4142 - acc: 0.7261\n",
      "Epoch 78/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.4030 - acc: 0.7284\n",
      "Epoch 79/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3893 - acc: 0.7293\n",
      "Epoch 80/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3704 - acc: 0.7304\n",
      "Epoch 81/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3665 - acc: 0.7323\n",
      "Epoch 82/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3561 - acc: 0.7355\n",
      "Epoch 83/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3416 - acc: 0.7365\n",
      "Epoch 84/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3250 - acc: 0.7390\n",
      "Epoch 85/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3068 - acc: 0.7426\n",
      "Epoch 86/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.3039 - acc: 0.7458\n",
      "Epoch 87/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2953 - acc: 0.7456\n",
      "Epoch 88/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2887 - acc: 0.7467\n",
      "Epoch 89/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2886 - acc: 0.7500\n",
      "Epoch 90/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2712 - acc: 0.7509\n",
      "Epoch 91/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2552 - acc: 0.7533\n",
      "Epoch 92/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2646 - acc: 0.7518\n",
      "Epoch 93/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2534 - acc: 0.7515\n",
      "Epoch 94/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2280 - acc: 0.7574\n",
      "Epoch 95/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2181 - acc: 0.7592\n",
      "Epoch 96/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2159 - acc: 0.7612\n",
      "Epoch 97/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2031 - acc: 0.7627\n",
      "Epoch 98/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2050 - acc: 0.7626\n",
      "Epoch 99/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.2005 - acc: 0.7620\n",
      "Epoch 100/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1913 - acc: 0.7648\n",
      "Epoch 101/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1843 - acc: 0.7652\n",
      "Epoch 102/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1792 - acc: 0.7666\n",
      "Epoch 103/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1672 - acc: 0.7675\n",
      "Epoch 104/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1617 - acc: 0.7677\n",
      "Epoch 105/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1548 - acc: 0.7683\n",
      "Epoch 106/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1547 - acc: 0.7690\n",
      "Epoch 107/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1430 - acc: 0.7682\n",
      "Epoch 108/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1362 - acc: 0.7724\n",
      "Epoch 109/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1314 - acc: 0.7723\n",
      "Epoch 110/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1242 - acc: 0.7730\n",
      "Epoch 111/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1183 - acc: 0.7758\n",
      "Epoch 112/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1275 - acc: 0.7705\n",
      "Epoch 113/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1134 - acc: 0.7732\n",
      "Epoch 114/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.1033 - acc: 0.7747\n",
      "Epoch 115/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0966 - acc: 0.7785\n",
      "Epoch 116/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0872 - acc: 0.7806\n",
      "Epoch 117/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0899 - acc: 0.7756\n",
      "Epoch 118/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0805 - acc: 0.7816\n",
      "Epoch 119/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0807 - acc: 0.7779\n",
      "Epoch 120/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0791 - acc: 0.7784\n",
      "Epoch 121/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0777 - acc: 0.7774\n",
      "Epoch 122/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0634 - acc: 0.7817\n",
      "Epoch 123/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0548 - acc: 0.7827\n",
      "Epoch 124/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0682 - acc: 0.7805\n",
      "Epoch 125/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0570 - acc: 0.7817\n",
      "Epoch 126/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0528 - acc: 0.7843\n",
      "Epoch 127/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0483 - acc: 0.7819\n",
      "Epoch 128/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0467 - acc: 0.7853\n",
      "Epoch 129/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0453 - acc: 0.7844\n",
      "Epoch 130/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0436 - acc: 0.7838\n",
      "Epoch 131/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0355 - acc: 0.7845\n",
      "Epoch 132/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0438 - acc: 0.7829\n",
      "Epoch 133/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0246 - acc: 0.7879\n",
      "Epoch 134/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0217 - acc: 0.7876\n",
      "Epoch 135/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0155 - acc: 0.7878\n",
      "Epoch 136/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0139 - acc: 0.7899\n",
      "Epoch 137/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0185 - acc: 0.7878\n",
      "Epoch 138/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0113 - acc: 0.7884\n",
      "Epoch 139/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0125 - acc: 0.7877\n",
      "Epoch 140/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0159 - acc: 0.7869\n",
      "Epoch 141/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0097 - acc: 0.7900\n",
      "Epoch 142/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0044 - acc: 0.7894\n",
      "Epoch 143/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0030 - acc: 0.7862\n",
      "Epoch 144/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 1.0046 - acc: 0.7879\n",
      "Epoch 145/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9972 - acc: 0.7900\n",
      "Epoch 146/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9893 - acc: 0.7907\n",
      "Epoch 147/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9815 - acc: 0.7939\n",
      "Epoch 148/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9807 - acc: 0.7923\n",
      "Epoch 149/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9905 - acc: 0.7880\n",
      "Epoch 150/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9831 - acc: 0.7905\n",
      "Epoch 151/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9776 - acc: 0.7903\n",
      "Epoch 152/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9691 - acc: 0.7933\n",
      "Epoch 153/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9765 - acc: 0.7926\n",
      "Epoch 154/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9718 - acc: 0.7922\n",
      "Epoch 155/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9703 - acc: 0.7923\n",
      "Epoch 156/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9721 - acc: 0.7905\n",
      "Epoch 157/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9671 - acc: 0.7923\n",
      "Epoch 158/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9690 - acc: 0.7905\n",
      "Epoch 159/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9711 - acc: 0.7921\n",
      "Epoch 160/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9605 - acc: 0.7937\n",
      "Epoch 161/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9592 - acc: 0.7938\n",
      "Epoch 162/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9612 - acc: 0.7903\n",
      "Epoch 163/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9617 - acc: 0.7936\n",
      "Epoch 164/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9463 - acc: 0.7956\n",
      "Epoch 165/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9480 - acc: 0.7929\n",
      "Epoch 166/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9437 - acc: 0.7985\n",
      "Epoch 167/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9471 - acc: 0.7953\n",
      "Epoch 168/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9417 - acc: 0.7940: 0s - loss: 0.9420 - ac\n",
      "Epoch 169/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9533 - acc: 0.7923\n",
      "Epoch 170/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9428 - acc: 0.7950\n",
      "Epoch 171/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9490 - acc: 0.7940\n",
      "Epoch 172/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9359 - acc: 0.7981\n",
      "Epoch 173/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9361 - acc: 0.7948\n",
      "Epoch 174/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9333 - acc: 0.7975\n",
      "Epoch 175/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9343 - acc: 0.7956\n",
      "Epoch 176/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9313 - acc: 0.7958\n",
      "Epoch 177/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9305 - acc: 0.7963\n",
      "Epoch 178/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9279 - acc: 0.7969\n",
      "Epoch 179/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9217 - acc: 0.7973\n",
      "Epoch 180/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9204 - acc: 0.7979\n",
      "Epoch 181/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9286 - acc: 0.7950\n",
      "Epoch 182/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9162 - acc: 0.7976\n",
      "Epoch 183/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9261 - acc: 0.7973\n",
      "Epoch 184/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9192 - acc: 0.7949\n",
      "Epoch 185/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9307 - acc: 0.7934\n",
      "Epoch 186/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9176 - acc: 0.7962\n",
      "Epoch 187/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9150 - acc: 0.7983: 1s \n",
      "Epoch 188/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9163 - acc: 0.7970\n",
      "Epoch 189/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9244 - acc: 0.7948\n",
      "Epoch 190/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9128 - acc: 0.7981\n",
      "Epoch 191/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9112 - acc: 0.7998\n",
      "Epoch 192/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9079 - acc: 0.7974\n",
      "Epoch 193/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9155 - acc: 0.7953\n",
      "Epoch 194/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9138 - acc: 0.7973\n",
      "Epoch 195/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9071 - acc: 0.7974\n",
      "Epoch 196/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9098 - acc: 0.7988:\n",
      "Epoch 197/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9057 - acc: 0.7994\n",
      "Epoch 198/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9025 - acc: 0.7979\n",
      "Epoch 199/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9119 - acc: 0.7960\n",
      "Epoch 200/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9074 - acc: 0.7948\n",
      "Epoch 201/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8999 - acc: 0.8000\n",
      "Epoch 202/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8934 - acc: 0.7985\n",
      "Epoch 203/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8971 - acc: 0.7984\n",
      "Epoch 204/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8905 - acc: 0.7996\n",
      "Epoch 205/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8898 - acc: 0.8003\n",
      "Epoch 206/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8978 - acc: 0.7982\n",
      "Epoch 207/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.9030 - acc: 0.7969\n",
      "Epoch 208/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8956 - acc: 0.7997\n",
      "Epoch 209/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8825 - acc: 0.8010\n",
      "Epoch 210/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8877 - acc: 0.7995\n",
      "Epoch 211/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8885 - acc: 0.7992\n",
      "Epoch 212/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8932 - acc: 0.7980\n",
      "Epoch 213/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 0.8854 - acc: 0.8002\n",
      "Epoch 214/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8903 - acc: 0.7983\n",
      "Epoch 215/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8826 - acc: 0.7989\n",
      "Epoch 216/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8813 - acc: 0.8011\n",
      "Epoch 217/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8890 - acc: 0.8002\n",
      "Epoch 218/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8833 - acc: 0.7989\n",
      "Epoch 219/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8793 - acc: 0.8006\n",
      "Epoch 220/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8752 - acc: 0.8027\n",
      "Epoch 221/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8805 - acc: 0.7999\n",
      "Epoch 222/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8790 - acc: 0.8016\n",
      "Epoch 223/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8833 - acc: 0.7995\n",
      "Epoch 224/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8894 - acc: 0.7982\n",
      "Epoch 225/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8778 - acc: 0.8021\n",
      "Epoch 226/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8730 - acc: 0.8024\n",
      "Epoch 227/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8697 - acc: 0.8017\n",
      "Epoch 228/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8791 - acc: 0.7999\n",
      "Epoch 229/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8771 - acc: 0.8002\n",
      "Epoch 230/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8734 - acc: 0.8015\n",
      "Epoch 231/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8772 - acc: 0.8002\n",
      "Epoch 232/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8729 - acc: 0.8001\n",
      "Epoch 233/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8750 - acc: 0.7984\n",
      "Epoch 234/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8652 - acc: 0.8018\n",
      "Epoch 235/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8665 - acc: 0.8002\n",
      "Epoch 236/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8707 - acc: 0.7998\n",
      "Epoch 237/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8711 - acc: 0.8014\n",
      "Epoch 238/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8650 - acc: 0.8024\n",
      "Epoch 239/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8685 - acc: 0.7998\n",
      "Epoch 240/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8667 - acc: 0.8010\n",
      "Epoch 241/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8613 - acc: 0.8031\n",
      "Epoch 242/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8626 - acc: 0.7997\n",
      "Epoch 243/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8631 - acc: 0.8040\n",
      "Epoch 244/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8597 - acc: 0.8010\n",
      "Epoch 245/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8572 - acc: 0.8030\n",
      "Epoch 246/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8688 - acc: 0.8020\n",
      "Epoch 247/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8626 - acc: 0.8008\n",
      "Epoch 248/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8631 - acc: 0.8005\n",
      "Epoch 249/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8548 - acc: 0.8060\n",
      "Epoch 250/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8518 - acc: 0.8053\n",
      "Epoch 251/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8550 - acc: 0.8012\n",
      "Epoch 252/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8617 - acc: 0.8010\n",
      "Epoch 253/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8566 - acc: 0.8027\n",
      "Epoch 254/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8612 - acc: 0.7992\n",
      "Epoch 255/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8593 - acc: 0.8001\n",
      "Epoch 256/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8613 - acc: 0.7994\n",
      "Epoch 257/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8616 - acc: 0.8002\n",
      "Epoch 258/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8543 - acc: 0.8018: 1s - loss: 0\n",
      "Epoch 259/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8517 - acc: 0.8046\n",
      "Epoch 260/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8484 - acc: 0.8030\n",
      "Epoch 261/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8523 - acc: 0.8036\n",
      "Epoch 262/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8539 - acc: 0.8006\n",
      "Epoch 263/300\n",
      "20971/20971 [==============================] - 47s 2ms/step - loss: 0.8552 - acc: 0.8019\n",
      "Epoch 264/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8528 - acc: 0.8030\n",
      "Epoch 265/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8585 - acc: 0.7992\n",
      "Epoch 266/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8486 - acc: 0.8036\n",
      "Epoch 267/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8527 - acc: 0.8039\n",
      "Epoch 268/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8464 - acc: 0.8029\n",
      "Epoch 269/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8545 - acc: 0.8012\n",
      "Epoch 270/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8474 - acc: 0.8033\n",
      "Epoch 271/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8500 - acc: 0.7999\n",
      "Epoch 272/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8509 - acc: 0.8019\n",
      "Epoch 273/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8499 - acc: 0.8028\n",
      "Epoch 274/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8482 - acc: 0.8031\n",
      "Epoch 275/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8494 - acc: 0.8014\n",
      "Epoch 276/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8457 - acc: 0.8021\n",
      "Epoch 277/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8415 - acc: 0.8025\n",
      "Epoch 278/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8493 - acc: 0.8037\n",
      "Epoch 279/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8506 - acc: 0.8021\n",
      "Epoch 280/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8445 - acc: 0.8028\n",
      "Epoch 281/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8369 - acc: 0.8030\n",
      "Epoch 282/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8506 - acc: 0.7999\n",
      "Epoch 283/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8476 - acc: 0.7992\n",
      "Epoch 284/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8469 - acc: 0.8032\n",
      "Epoch 285/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8473 - acc: 0.7994\n",
      "Epoch 286/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8333 - acc: 0.8035\n",
      "Epoch 287/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8444 - acc: 0.8030\n",
      "Epoch 288/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8533 - acc: 0.7999\n",
      "Epoch 289/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8472 - acc: 0.8008\n",
      "Epoch 290/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8402 - acc: 0.8030\n",
      "Epoch 291/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8288 - acc: 0.8036\n",
      "Epoch 292/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8384 - acc: 0.8042\n",
      "Epoch 293/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8303 - acc: 0.8019\n",
      "Epoch 294/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8316 - acc: 0.8033\n",
      "Epoch 295/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8278 - acc: 0.8037\n",
      "Epoch 296/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8312 - acc: 0.8054\n",
      "Epoch 297/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8295 - acc: 0.8044\n",
      "Epoch 298/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8406 - acc: 0.7995\n",
      "Epoch 299/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8388 - acc: 0.8032\n",
      "Epoch 300/300\n",
      "20971/20971 [==============================] - 46s 2ms/step - loss: 0.8341 - acc: 0.8037\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(predictors, \n",
    "                    label, \n",
    "                    epochs=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load up on guns, bring your friends It's fun to lose it take myself again was yeah yeah yeah yeah yeah yeah she down and blame course in hell forever by searching wrong and nothing told myself again just too far in by my soul in his in from you you are it's all and you can rattles the world they betray then we will find you holds you from us anymore engines ground and time to kiss your ass goodbye to the wind new of from the new built the lights from the sea start from this hell of green hell green hell green hell green hell hell hell soul\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Load up on guns, bring your friends It's fun to lose\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I can't remember anything Can't tell if this is true or dream i die i was just hope play by the weaker race hammer down faster scarred with fire with fire with fire forever but it's still i'm through the chosen one green hell green hell death green hell hell green hell death heart hell make hell have step make it go yourself you can rattles the damn it all and laugh and all the same are i deny i deny i deny i deny i start and strong and one by my place again the glory or swing the land of right down into time on the trumpets diem baby green\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"I can't remember anything Can't tell if this is true or dream\"\n",
    "next_words = 100\n",
    "  \n",
    "for _ in range(next_words):\n",
    "    token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "    predicted = model.predict_classes(token_list, verbose=0)\n",
    "    output_word = \"\"\n",
    "    for word, index in tokenizer.word_index.items():\n",
    "        if index == predicted:\n",
    "            output_word = word\n",
    "            break\n",
    "    seed_text += \" \" + output_word\n",
    "print(seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
